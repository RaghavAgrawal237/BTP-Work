{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-07T17:55:13.404361Z","iopub.execute_input":"2022-06-07T17:55:13.405043Z","iopub.status.idle":"2022-06-07T17:55:13.420148Z","shell.execute_reply.started":"2022-06-07T17:55:13.405007Z","shell.execute_reply":"2022-06-07T17:55:13.419124Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"/kaggle/input/torsomotionremovednan/torso.h5\n/kaggle/input/torsomotionremovednan/tm3.txt\n/kaggle/input/torsomotionremovednan/torso-motion.h5\n/kaggle/input/torsomotionremovednan/tm2.txt\n/kaggle/input/torsomotionremovednan/tm1.txt\n/kaggle/input/shl-dataset/Torso_Motion3.txt\n/kaggle/input/shl-dataset/Label.txt\n/kaggle/input/shl-dataset/Torso_Motion.txt\n/kaggle/input/shl-dataset/Label2.txt\n/kaggle/input/shl-dataset/Label3.txt\n/kaggle/input/shl-dataset/Torso_Motion2.txt\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport h5py\ndef read_motion():\n    motions =[]\n    torso_motion = [\"/kaggle/input/torsomotionremovednan/tm1.txt\",\"/kaggle/input/torsomotionremovednan/tm2.txt\",\"/kaggle/input/torsomotionremovednan/tm3.txt\"]\n    labels = [\"/kaggle/input/shl-dataset/Label.txt\",\"/kaggle/input/shl-dataset/Label2.txt\",\"/kaggle/input/shl-dataset/Label3.txt\"]\n    motions = torso_motion\n    data = np.array([]) \n    for i, file in enumerate(motions):\n        np_motion = np.loadtxt(file)\n#         np_motion = downsize(np_motion)\n        print(np_motion.shape)\n        start = np_motion[0,0].astype(np.int64)\n        end = np_motion[-1,0].astype(np.int64)\n        label = labels[i]\n        np_label = np.loadtxt(label)\n        start_index = np.where(np_label == start)[0][0]\n        end_index = np.where(np_label == end)[0][0] \n        np_label = find_labels(np_label,start_index,end_index)\n        folder_id = np.full(np_label.shape, i) # put folder_id in the last column\n        concatenate = np.concatenate((np_motion,np_label,folder_id),axis=1)\n        if i == 0:\n            data = concatenate\n        else:\n            data = np.concatenate((data,concatenate))\n\n    print(data.shape)\n    print(data[:5,:])\n    for i in range(1, 20):\n        data[:,i:i+1] = np.square(data[:,i:i+1])\n    i = 1\n    print(data[:5,:])\n    while(i<20):\n        if(i != 10):\n            data[:,i:i+1] = data[:,i:i+1]+data[:,i+1:i+2]+data[:,i+2:i+3]\n            data[:,i:i+1] = np.sqrt(data[:,i:i+1])\n            i=i+3\n        else:\n            data[:,i:i+1] = data[:,i:i+1]+data[:,i+1:i+2]+data[:,i+2:i+3]+data[:,i+3:i+4]\n            data[:,i:i+1] = np.sqrt(data[:,i:i+1])\n            i=i+4\n    data = np.delete(data, [2,3,5,6,8,9,11,12,13,15,16,18,19], 1)\n    print(data[:5,:])\n    return data\n\n# def downsize(data):# data is numpy array\n#     downsample_size = 10\n#     data = data[::downsample_size,:]\n#     return data\n\ndef find_labels(labels,start_index, end_index):\n#     interval = 10\n    interval=1\n    label_col_index = 1 # the 2 column of Label.txt\n    data = labels[start_index: end_index+1:interval, label_col_index].reshape(-1,1) # need to be the shape like (n,1), so that it can be concatenate later\n    return data\n\ndef save_data(data,file_name): # save the data in h5 format\n    f = h5py.File(file_name,'w')\n    for key in data:\n        print(key)\n        f.create_dataset(key,data = data[key])       \n    f.close()\n\ndef segment(data, window_size): # data is numpy array\n    n = len(data)\n    X = []\n    y = []\n    start = 0\n    end = 0\n    while start + window_size - 1 < n:\n        end = start + window_size-1\n        if data[start][-2]!=0 and data[start][-2] == data[end][-2] and data[start][-1] == data[end][-1] : # if the frame contains the same activity and from the same object\n            X.append(data[start:(end+1),1:-2])\n            y_label = data[start][-2]\n            if y_label == 8:\n                y.append(0) # change label 8 to 0\n            else:\n                y.append(data[start][-2])\n            start += window_size//2 # 50% overlap\n        else: # if the frame contains different activities or from different objects, find the next start point\n            while start + window_size-1 < n:\n                if data[start][-2] == 0 or data[start][-2] != data[start+1][-2]:\n                    break\n                start += 1\n            start += 1\n    print(np.asarray(X).shape, np.asarray(y).shape)\n    return {'inputs' : np.asarray(X), 'labels': np.asarray(y,dtype=int)}\n    print('Done.')  \n\n\nif __name__ == \"__main__\":\n    file = \"torso.h5\" \n    data = read_motion()\n    segment_data = segment(data,500)\n    save_data(segment_data, file)","metadata":{"execution":{"iopub.status.busy":"2022-06-07T17:55:13.453694Z","iopub.execute_input":"2022-06-07T17:55:13.454309Z","iopub.status.idle":"2022-06-07T18:02:32.343414Z","shell.execute_reply.started":"2022-06-07T17:55:13.454276Z","shell.execute_reply":"2022-06-07T18:02:32.342319Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"(4644801, 23)\n(3898101, 23)\n(3396501, 23)\n(11939403, 25)\n[[ 1.49812030e+12  3.70293128e+00  5.28423412e+00  3.29553497e+00\n   2.13670505e-03 -7.76708126e-04  1.89031372e-03 -7.27444035e+00\n  -2.06223446e+01 -1.76457330e+01  4.50220033e-01  2.79286839e-01\n  -9.52012981e-02  8.68656796e-02  3.72865164e+00  5.28973818e+00\n   3.26692538e+00 -3.82713359e-03  3.02699038e-02  4.12063670e-02\n   1.00820050e+03  0.00000000e+00  0.00000000e+00  0.00000000e+00\n   0.00000000e+00]\n [ 1.49812030e+12  3.70293128e+00  5.28423412e+00  3.29553497e+00\n   2.13670505e-03 -7.76708126e-04  1.89031372e-03 -7.27444035e+00\n  -2.06223446e+01 -1.76457330e+01  4.50220033e-01  2.79286839e-01\n  -9.52012981e-02  8.68656796e-02  3.72865164e+00  5.28973818e+00\n   3.26692538e+00 -3.82713359e-03  3.02699038e-02  4.12063670e-02\n   1.00820050e+03  0.00000000e+00  0.00000000e+00  0.00000000e+00\n   0.00000000e+00]\n [ 1.49812030e+12  3.70293128e+00  5.28423412e+00  3.29553497e+00\n   2.13670505e-03 -7.76708126e-04  1.89031372e-03 -7.27444035e+00\n  -2.06223446e+01 -1.76457330e+01  4.50220033e-01  2.79286839e-01\n  -9.52012981e-02  8.68656796e-02  3.72865164e+00  5.28973818e+00\n   3.26692538e+00 -3.82713359e-03  3.02699038e-02  4.12063670e-02\n   1.00820050e+03  0.00000000e+00  0.00000000e+00  0.00000000e+00\n   0.00000000e+00]\n [ 1.49812030e+12  3.70293128e+00  5.28423412e+00  3.29553497e+00\n   2.13670505e-03 -7.76708126e-04  1.89031372e-03 -7.27444035e+00\n  -2.06223446e+01 -1.76457330e+01  4.50220033e-01  2.79286839e-01\n  -9.52012981e-02  8.68656796e-02  3.72865164e+00  5.28973818e+00\n   3.26692538e+00 -3.82713359e-03  3.02699038e-02  4.12063670e-02\n   1.00820050e+03  0.00000000e+00  0.00000000e+00  0.00000000e+00\n   0.00000000e+00]\n [ 1.49812030e+12  3.70293128e+00  5.28423412e+00  3.29553497e+00\n   2.13670505e-03 -7.76708126e-04  1.89031372e-03 -7.27444035e+00\n  -2.06223446e+01 -1.76457330e+01  4.50220033e-01  2.79286839e-01\n  -9.52012981e-02  8.68656796e-02  3.72865164e+00  5.28973818e+00\n   3.26692538e+00 -3.82713359e-03  3.02699038e-02  4.12063670e-02\n   1.00820050e+03  0.00000000e+00  0.00000000e+00  0.00000000e+00\n   0.00000000e+00]]\n[[1.49812030e+12 1.37117001e+01 2.79231302e+01 1.08605507e+01\n  4.56550846e-06 6.03275513e-07 3.57328595e-06 5.29174824e+01\n  4.25281099e+02 3.11371893e+02 2.02698078e-01 7.80011386e-02\n  9.06328716e-03 7.54564629e-03 1.39028430e+01 2.79813300e+01\n  1.06728014e+01 1.46469515e-05 9.16267078e-04 1.69796468e-03\n  1.00820050e+03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n  0.00000000e+00]\n [1.49812030e+12 1.37117001e+01 2.79231302e+01 1.08605507e+01\n  4.56550846e-06 6.03275513e-07 3.57328595e-06 5.29174824e+01\n  4.25281099e+02 3.11371893e+02 2.02698078e-01 7.80011386e-02\n  9.06328716e-03 7.54564629e-03 1.39028430e+01 2.79813300e+01\n  1.06728014e+01 1.46469515e-05 9.16267078e-04 1.69796468e-03\n  1.00820050e+03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n  0.00000000e+00]\n [1.49812030e+12 1.37117001e+01 2.79231302e+01 1.08605507e+01\n  4.56550846e-06 6.03275513e-07 3.57328595e-06 5.29174824e+01\n  4.25281099e+02 3.11371893e+02 2.02698078e-01 7.80011386e-02\n  9.06328716e-03 7.54564629e-03 1.39028430e+01 2.79813300e+01\n  1.06728014e+01 1.46469515e-05 9.16267078e-04 1.69796468e-03\n  1.00820050e+03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n  0.00000000e+00]\n [1.49812030e+12 1.37117001e+01 2.79231302e+01 1.08605507e+01\n  4.56550846e-06 6.03275513e-07 3.57328595e-06 5.29174824e+01\n  4.25281099e+02 3.11371893e+02 2.02698078e-01 7.80011386e-02\n  9.06328716e-03 7.54564629e-03 1.39028430e+01 2.79813300e+01\n  1.06728014e+01 1.46469515e-05 9.16267078e-04 1.69796468e-03\n  1.00820050e+03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n  0.00000000e+00]\n [1.49812030e+12 1.37117001e+01 2.79231302e+01 1.08605507e+01\n  4.56550846e-06 6.03275513e-07 3.57328595e-06 5.29174824e+01\n  4.25281099e+02 3.11371893e+02 2.02698078e-01 7.80011386e-02\n  9.06328716e-03 7.54564629e-03 1.39028430e+01 2.79813300e+01\n  1.06728014e+01 1.46469515e-05 9.16267078e-04 1.69796468e-03\n  1.00820050e+03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n  0.00000000e+00]]\n[[1.49812030e+12 7.24536963e+00 2.95669916e-03 2.80992967e+01\n  5.45259709e-01 7.24961892e+00 5.12725922e-02 1.00820050e+03\n  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n [1.49812030e+12 7.24536963e+00 2.95669916e-03 2.80992967e+01\n  5.45259709e-01 7.24961892e+00 5.12725922e-02 1.00820050e+03\n  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n [1.49812030e+12 7.24536963e+00 2.95669916e-03 2.80992967e+01\n  5.45259709e-01 7.24961892e+00 5.12725922e-02 1.00820050e+03\n  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n [1.49812030e+12 7.24536963e+00 2.95669916e-03 2.80992967e+01\n  5.45259709e-01 7.24961892e+00 5.12725922e-02 1.00820050e+03\n  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n [1.49812030e+12 7.24536963e+00 2.95669916e-03 2.80992967e+01\n  5.45259709e-01 7.24961892e+00 5.12725922e-02 1.00820050e+03\n  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n(24260, 500, 9) (24260,)\ninputs\nlabels\n","output_type":"stream"}]},{"cell_type":"code","source":"print(data[:5,:])","metadata":{"execution":{"iopub.status.busy":"2022-06-07T18:02:32.349205Z","iopub.execute_input":"2022-06-07T18:02:32.351447Z","iopub.status.idle":"2022-06-07T18:02:32.356849Z","shell.execute_reply.started":"2022-06-07T18:02:32.351407Z","shell.execute_reply":"2022-06-07T18:02:32.355775Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"[[1.49812030e+12 7.24536963e+00 2.95669916e-03 2.80992967e+01\n  5.45259709e-01 7.24961892e+00 5.12725922e-02 1.00820050e+03\n  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n [1.49812030e+12 7.24536963e+00 2.95669916e-03 2.80992967e+01\n  5.45259709e-01 7.24961892e+00 5.12725922e-02 1.00820050e+03\n  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n [1.49812030e+12 7.24536963e+00 2.95669916e-03 2.80992967e+01\n  5.45259709e-01 7.24961892e+00 5.12725922e-02 1.00820050e+03\n  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n [1.49812030e+12 7.24536963e+00 2.95669916e-03 2.80992967e+01\n  5.45259709e-01 7.24961892e+00 5.12725922e-02 1.00820050e+03\n  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n [1.49812030e+12 7.24536963e+00 2.95669916e-03 2.80992967e+01\n  5.45259709e-01 7.24961892e+00 5.12725922e-02 1.00820050e+03\n  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import stats\nimport tensorflow as tf\nfrom sklearn import metrics\nimport h5py\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras import regularizers\nfrom tensorflow.keras.layers import Input, Conv2D, Dense, Flatten, Dropout, SimpleRNN, GRU, LSTM, GlobalMaxPooling1D,GlobalMaxPooling2D,MaxPooling2D,BatchNormalization\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam, SGD\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nimport itertools\nfrom keras.utils.vis_utils import plot_model","metadata":{"execution":{"iopub.status.busy":"2022-06-07T18:27:51.034322Z","iopub.execute_input":"2022-06-07T18:27:51.034727Z","iopub.status.idle":"2022-06-07T18:27:51.042012Z","shell.execute_reply.started":"2022-06-07T18:27:51.034687Z","shell.execute_reply":"2022-06-07T18:27:51.041256Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"class models():\n    def __init__(self, path):\n        self.path = path\n        \n        \n    def read_h5(self):\n        f = h5py.File(path, 'r')\n        X = f.get('inputs')\n        y = f.get('labels') \n        \n        X = np.array(X)\n        y = np.array(y)\n        self.x_train, self.x_test, self.y_train, self.y_test = train_test_split(X, y, test_size=0.2, random_state = 1)\n        print(self.x_train.shape,self.y_train.shape)\n    def draw(self):\n        f1 = plt.figure(1)\n        plt.title('Loss')\n        plt.plot(self.r.history['loss'], label = 'loss')\n        plt.plot(self.r.history['val_loss'], label = 'val_loss')\n        plt.legend()\n        f1.show()\n        \n        f2 = plt.figure(2)\n        plt.plot(self.r.history['accuracy'], label = 'accuracy')\n        plt.plot(self.r.history['val_accuracy'], label = 'val_accuracy')\n        plt.legend()\n        f2.show()    \n    def cnn_model(self):\n        K = len(set(self.y_train))\n#         print(K)\n        \n        print(self.x_train.shape,self.y_train.shape)\n#         Input_shape should be a 4dim vectors as stated in the keras doc:\n        self.x_train = np.expand_dims(self.x_train, -1)\n        self.x_test = np.expand_dims(self.x_test,-1)\n        print(self.x_train.shape,self.y_train.shape)\n        \n        i = Input(shape=self.x_train[0].shape)\n        print(self.x_train[0].shape)\n        x = Conv2D(16, (3,3), strides = 2, activation = 'relu',padding='same',kernel_regularizer=regularizers.l2(0.0005))(i)\n        x = BatchNormalization()(x)\n        x = Dropout(0.2)(x)\n        x = Flatten()(x)    \n        x = Dropout(0.2)(x)\n        x = Dense(128,activation = 'relu')(x)\n        x = BatchNormalization()(x)\n        x = Dropout(0.2)(x)\n        x = Dense(K, activation = 'softmax')(x)       \n        self.model = Model(i,x)\n        self.model.compile(optimizer = Adam(learning_rate=0.0005),\n              loss = 'sparse_categorical_crossentropy',\n              metrics = ['accuracy'])\n        \n        self.r = self.model.fit(self.x_train, self.y_train, validation_data = (self.x_test, self.y_test), epochs = 200, batch_size = 128 )\n        print(self.model.summary())\n        return self.r\n    \n    def cnn_model_2(self):\n        K = len(set(self.y_train))\n#         print(K)\n        \n        print(self.x_train.shape,self.y_train.shape)\n#         Input_shape should be a 4dim vectors as stated in the keras doc:\n        self.x_train = np.expand_dims(self.x_train, -1)\n        self.x_test = np.expand_dims(self.x_test,-1)\n        print(self.x_train.shape,self.y_train.shape)\n        \n        i = Input(shape=self.x_train[0].shape)\n        print(self.x_train[0].shape)\n        x = Conv2D(32, (1, 5), strides = (1,1), activation = 'relu',padding='same',kernel_regularizer=regularizers.l2(0.0005))(i)\n        x = BatchNormalization()(x)\n        x = Dropout(0.2)(x)\n        x = MaxPooling2D(pool_size=(1,2), strides=(1,2))\n        #x = Flatten()(x)    \n        #x = Dropout(0.2)(x)\n        x = Dense(128,activation = 'relu')(x)\n        x = Conv2D(64, (1, 3), strides = (1,1), activation = 'relu',padding='same',kernel_regularizer=regularizers.l2(0.0005))(i)\n        x = BatchNormalization()(x)\n        x = Dropout(0.2)(x)\n        x = MaxPooling2D(pool_size=(1,2), strides=(1,2))\n        x = Flatten()(x)  \n        x = Dropout(0.2)(x)\n        x = Conv2D(128, (1, 3), strides = (1,1), activation = 'relu',padding='same',kernel_regularizer=regularizers.l2(0.0005))(i)\n        x = Flatten()(x)\n        x = Bidirectional(LSTM(64, return_sequences=True))(x)\n        x = Bidirectional(LSTM(64))(x)\n        x = Dense(8, activation = 'softmax')(x)\n        \n        self.model = Model(i,x)\n        self.model.compile(optimizer = Adam(learning_rate=0.0005),\n              loss = 'sparse_categorical_crossentropy',\n              metrics = ['accuracy'])\n        \n        self.r = self.model.fit(self.x_train, self.y_train, validation_data = (self.x_test, self.y_test), epochs = 200, batch_size = 128 )\n        print(self.model.summary())\n        return self.r\n    \n    def rnn_model(self):\n        K = len(set(self.y_train))\n        i = Input(shape = self.x_train[0].shape)\n        x = LSTM(128, return_sequences=True)(i)\n        #x = LSTM(128, return_sequences=True)(i)\n        x = Dense(128,activation = 'relu')(x)\n        x = GlobalMaxPooling1D()(x)\n        x = Dense(K,activation = 'softmax')(x)\n        self.model = Model(i,x)      \n        self.model.compile(optimizer = Adam(lr=0.0005),\n              loss = 'sparse_categorical_crossentropy',\n              metrics = ['accuracy'])\n        self.r = self.model.fit(self.x_train, self.y_train, validation_data = (self.x_test, self.y_test), epochs = 200, batch_size = 64)\n        #self.r = model.fit(X, y, validation_split = 0.2, epochs = 10, batch_size = 32 )\n        print(self.model.summary())\n        return self.r\n    def con_matrix(self):\n        K = len(set(self.y_train))\n        self.y_pred = self.model.predict(self.x_test).argmax(axis=1)\n        cm = confusion_matrix(self.y_test,self.y_pred)\n        self.plot_confusion_matrix(cm,list(range(K)))\n    \n    def plot_confusion_matrix(self, cm, classes, normalize = False, title='Confusion matrix', cmap=plt.cm.Blues):\n        if normalize:\n            cm = cm.astype('float') / cm.sum(axis=1)[:,np.newaxis]\n            print(\"Normalized confusion matrix\")\n        else:\n            print(\"Confusion matrix, without normalization\")\n        print(cm)\n        f3 = plt.figure(3)\n        plt.imshow(cm, interpolation='nearest', cmap=cmap)\n        plt.title(title)\n        plt.colorbar()\n        tick_marks = np.arange(len(classes))\n        plt.xticks(tick_marks, classes, rotation=45)\n        plt.yticks(tick_marks, classes)\n        \n        fmt = '.2f' if normalize else 'd' \n        thresh = cm.max()/2.\n        for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n            plt.text(j, i, format(cm[i, j], fmt),\n                     horizontalalignment = \"center\",\n                     color = \"white\" if cm[i, j] > thresh else \"black\")\n            plt.tight_layout()\n            plt.ylabel('True label')\n            plt.xlabel('predicted label')\n            f3.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-06-07T18:30:11.866293Z","iopub.execute_input":"2022-06-07T18:30:11.867134Z","iopub.status.idle":"2022-06-07T18:30:11.940299Z","shell.execute_reply.started":"2022-06-07T18:30:11.867078Z","shell.execute_reply":"2022-06-07T18:30:11.939058Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"model_name = \"cnn\" \npath='./torso.h5'\nmotion = models(path)\nmotion.read_h5()\nmodel=motion.cnn_model_2()\nmotion.draw()\nmotion.con_matrix()\n#model=motion.rnn_model()\n#motion.draw()\n#motion.con_matrix()","metadata":{"execution":{"iopub.status.busy":"2022-06-07T18:30:12.463123Z","iopub.execute_input":"2022-06-07T18:30:12.463529Z","iopub.status.idle":"2022-06-07T18:30:15.394650Z","shell.execute_reply.started":"2022-06-07T18:30:12.463469Z","shell.execute_reply":"2022-06-07T18:30:15.393403Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"(19408, 500, 9) (19408,)\n(19408, 500, 9) (19408,)\n(19408, 500, 9, 1) (19408,)\n(500, 9, 1)\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_33/3604825878.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmotion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmotion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_h5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmotion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcnn_model_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mmotion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmotion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcon_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_33/4221780647.py\u001b[0m in \u001b[0;36mcnn_model_2\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;31m#x = Flatten()(x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;31m#x = Dropout(0.2)(x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkernel_regularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregularizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.0005\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1018\u001b[0m         training=training_mode):\n\u001b[1;32m   1019\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1020\u001b[0;31m       \u001b[0minput_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1021\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0meager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m         \u001b[0mcall_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;31m# have a `shape` attribute.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Inputs to a layer should be tensors. Got: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: Inputs to a layer should be tensors. Got: <keras.layers.pooling.MaxPooling2D object at 0x7f63b86bfd10>"],"ename":"TypeError","evalue":"Inputs to a layer should be tensors. Got: <keras.layers.pooling.MaxPooling2D object at 0x7f63b86bfd10>","output_type":"error"}]},{"cell_type":"code","source":"data[:10, :]\n","metadata":{"execution":{"iopub.status.busy":"2022-06-07T18:06:05.067996Z","iopub.status.idle":"2022-06-07T18:06:05.068783Z","shell.execute_reply.started":"2022-06-07T18:06:05.068446Z","shell.execute_reply":"2022-06-07T18:06:05.068477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}